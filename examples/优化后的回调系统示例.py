#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ä¼˜åŒ–åçš„å›è°ƒç³»ç»Ÿä½¿ç”¨ç¤ºä¾‹

å±•ç¤ºå¦‚ä½•ä½¿ç”¨æ–°çš„å›è°ƒç³»ç»Ÿï¼Œå…¶ä¸­å›è°ƒå‡½æ•°å¯ä»¥ç›´æ¥è®¿é—®è®­ç»ƒå™¨çš„training_resultsï¼Œ
é¿å…å¤æ‚çš„å‚æ•°ä¼ é€’ã€‚
"""

import sys
import os
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from callbacks.base_callback import Callback, CallbackManager
from callbacks.early_stopping import EarlyStoppingCallback
from callbacks.plotting import PlottingCallback
from typing import Dict, Any, Optional


class MockTrainer:
    """
    æ¨¡æ‹Ÿè®­ç»ƒå™¨ç±»
    
    ç”¨äºæ¼”ç¤ºå›è°ƒç³»ç»Ÿçš„ä½¿ç”¨æ–¹å¼
    """
    
    def __init__(self):
        """
        åˆå§‹åŒ–æ¨¡æ‹Ÿè®­ç»ƒå™¨
        """
        self.training_results = {
            'train_loss': 0.0,
            'val_loss': 0.0,
            'train_acc': 0.0,
            'val_acc': 0.0,
            'learning_rate': 0.001,
            'gradient_norm': 0.0,
            'bitwise_success_rate': 0.0,
            'log2_success_rate': 0.0,
            'early_stopped': False,
            'best_epoch': 0
        }
    
    def simulate_training(self, epochs: int = 20):
        """
        æ¨¡æ‹Ÿè®­ç»ƒè¿‡ç¨‹
        
        æ¼”ç¤ºå¦‚ä½•åœ¨è®­ç»ƒå¾ªç¯ä¸­ä½¿ç”¨ä¼˜åŒ–åçš„å›è°ƒç³»ç»Ÿ
        
        Args:
            epochs (int): è®­ç»ƒè½®æ•°
        """
        print("ğŸš€ å¼€å§‹æ¨¡æ‹Ÿè®­ç»ƒè¿‡ç¨‹...")
        
        # åˆå§‹åŒ–å›è°ƒç®¡ç†å™¨å¹¶è®¾ç½®è®­ç»ƒå™¨å¼•ç”¨
        callback_manager = CallbackManager()
        callback_manager.set_trainer(self)  # å…³é”®æ­¥éª¤ï¼šè®¾ç½®è®­ç»ƒå™¨å¼•ç”¨
        
        # æ·»åŠ æ—©åœå›è°ƒ
        early_stopping = EarlyStoppingCallback(
            monitor='val_loss',
            patience=5,
            min_delta=0.001,
            mode='min'
        )
        callback_manager.add_callback(early_stopping)
        
        # æ·»åŠ ç»˜å›¾å›è°ƒï¼ˆåªåœ¨è®­ç»ƒç»“æŸæ—¶ç»˜åˆ¶ï¼‰
        plotting = PlottingCallback(
            save_dir="./demo_plots",
            experiment_name="callback_demo"
        )
        callback_manager.add_callback(plotting)
        
        # æ·»åŠ è‡ªå®šä¹‰å›è°ƒ
        custom_callback = CustomMetricsCallback()
        callback_manager.add_callback(custom_callback)
        
        # è®­ç»ƒå¼€å§‹
        callback_manager.on_train_begin()
        
        # æ¨¡æ‹Ÿè®­ç»ƒå¾ªç¯
        for epoch in range(epochs):
            # æ¨¡æ‹Ÿè®­ç»ƒæŒ‡æ ‡çš„å˜åŒ–
            self._simulate_epoch_metrics(epoch)
            
            print(f"Epoch {epoch + 1}/{epochs}:")
            print(f"  Train Loss: {self.training_results['train_loss']:.4f}")
            print(f"  Val Loss: {self.training_results['val_loss']:.4f}")
            print(f"  Train Acc: {self.training_results['train_acc']:.4f}")
            print(f"  Val Acc: {self.training_results['val_acc']:.4f}")
            
            # è°ƒç”¨å›è°ƒå‡½æ•° - æ³¨æ„ï¼šä¸éœ€è¦ä¼ é€’å¤æ‚çš„logså‚æ•°
            callback_results = callback_manager.on_epoch_end(epoch)
            
            # æ£€æŸ¥æ—©åœ
            if callback_results.get('early_stop', False):
                print(f"\nâ¹ï¸ æ—©åœè§¦å‘ï¼Œåœ¨ç¬¬ {epoch + 1} è½®åœæ­¢è®­ç»ƒ")
                break
            
            print("")
        
        # è®­ç»ƒç»“æŸ
        callback_manager.on_train_end()
        print("âœ… è®­ç»ƒå®Œæˆï¼")
    
    def _simulate_epoch_metrics(self, epoch: int):
        """
        æ¨¡æ‹Ÿæ¯ä¸ªepochçš„æŒ‡æ ‡å˜åŒ–
        
        Args:
            epoch (int): å½“å‰epochæ•°
        """
        import random
        import math
        
        # æ¨¡æ‹ŸæŸå¤±ä¸‹é™ï¼ˆå¸¦ä¸€äº›éšæœºæ³¢åŠ¨ï¼‰
        base_train_loss = 1.0 * math.exp(-epoch * 0.1) + random.uniform(-0.05, 0.05)
        base_val_loss = 1.1 * math.exp(-epoch * 0.08) + random.uniform(-0.08, 0.08)
        
        # æ¨¡æ‹Ÿå‡†ç¡®ç‡æå‡
        base_train_acc = min(0.95, 0.5 + epoch * 0.02 + random.uniform(-0.02, 0.02))
        base_val_acc = min(0.92, 0.45 + epoch * 0.018 + random.uniform(-0.03, 0.03))
        
        # æ›´æ–°training_results
        self.training_results.update({
            'train_loss': max(0.01, base_train_loss),
            'val_loss': max(0.01, base_val_loss),
            'train_acc': max(0.0, base_train_acc),
            'val_acc': max(0.0, base_val_acc),
            'learning_rate': 0.001 * (0.95 ** epoch),
            'gradient_norm': max(0.1, 2.0 - epoch * 0.08),
            'bitwise_success_rate': min(1.0, 0.3 + epoch * 0.03),
            'log2_success_rate': min(1.0, 0.2 + epoch * 0.025)
        })


class CustomMetricsCallback(Callback):
    """
    è‡ªå®šä¹‰æŒ‡æ ‡å›è°ƒå‡½æ•°ç¤ºä¾‹
    
    å±•ç¤ºå¦‚ä½•åˆ›å»ºè‡ªå®šä¹‰å›è°ƒå‡½æ•°ï¼Œç›´æ¥è®¿é—®è®­ç»ƒå™¨çš„æ•°æ®
    """
    
    def __init__(self):
        """
        åˆå§‹åŒ–è‡ªå®šä¹‰å›è°ƒ
        """
        super().__init__()
        self.best_val_acc = 0.0
        self.metrics_history = []
    
    def on_train_begin(self, logs: Optional[Dict[str, Any]] = None):
        """
        è®­ç»ƒå¼€å§‹æ—¶çš„åˆå§‹åŒ–
        
        Args:
            logs (dict, optional): é¢å¤–çš„è®­ç»ƒæ—¥å¿—ä¿¡æ¯ï¼ˆå¯é€‰ï¼‰
        """
        print("ğŸ“Š è‡ªå®šä¹‰æŒ‡æ ‡è¿½è¸ªå™¨å·²å¯åŠ¨")
        self.best_val_acc = 0.0
        self.metrics_history = []
    
    def on_epoch_end(self, epoch: int, logs: Optional[Dict[str, Any]] = None):
        """
        æ¯ä¸ªepochç»“æŸæ—¶çš„æŒ‡æ ‡åˆ†æ
        
        Args:
            epoch (int): å½“å‰epochæ•°
            logs (dict, optional): é¢å¤–çš„è®­ç»ƒæ—¥å¿—ä¿¡æ¯ï¼ˆå¯é€‰ï¼‰
        """
        # ç›´æ¥ä»è®­ç»ƒå™¨è·å–æ•°æ® - è¿™æ˜¯æ–°è®¾è®¡çš„æ ¸å¿ƒä¼˜åŠ¿
        training_results = self.get_training_results()
        if training_results is None:
            return
        
        current_val_acc = training_results.get('val_acc', 0.0)
        
        # è®°å½•æŒ‡æ ‡å†å²
        self.metrics_history.append({
            'epoch': epoch,
            'val_acc': current_val_acc,
            'train_loss': training_results.get('train_loss', 0.0),
            'val_loss': training_results.get('val_loss', 0.0)
        })
        
        # æ£€æŸ¥æ˜¯å¦æœ‰æ–°çš„æœ€ä½³éªŒè¯å‡†ç¡®ç‡
        if current_val_acc > self.best_val_acc:
            self.best_val_acc = current_val_acc
            print(f"  ğŸ¯ æ–°çš„æœ€ä½³éªŒè¯å‡†ç¡®ç‡: {current_val_acc:.4f}")
        
        # è®¡ç®—æ”¹è¿›ç‡
        if len(self.metrics_history) > 1:
            prev_val_acc = self.metrics_history[-2]['val_acc']
            improvement = current_val_acc - prev_val_acc
            if improvement > 0.01:
                print(f"  ğŸ“ˆ éªŒè¯å‡†ç¡®ç‡æ˜¾è‘—æå‡: +{improvement:.4f}")
            elif improvement < -0.01:
                print(f"  ğŸ“‰ éªŒè¯å‡†ç¡®ç‡ä¸‹é™: {improvement:.4f}")
    
    def on_train_end(self, logs: Optional[Dict[str, Any]] = None):
        """
        è®­ç»ƒç»“æŸæ—¶çš„æ€»ç»“æŠ¥å‘Š
        
        Args:
            logs (dict, optional): é¢å¤–çš„è®­ç»ƒæ—¥å¿—ä¿¡æ¯ï¼ˆå¯é€‰ï¼‰
        """
        print("\nğŸ“Š è‡ªå®šä¹‰æŒ‡æ ‡è¿½è¸ªå™¨æ€»ç»“æŠ¥å‘Š:")
        print(f"  æœ€ä½³éªŒè¯å‡†ç¡®ç‡: {self.best_val_acc:.4f}")
        print(f"  æ€»è®­ç»ƒè½®æ•°: {len(self.metrics_history)}")
        
        if self.metrics_history:
            final_metrics = self.metrics_history[-1]
            print(f"  æœ€ç»ˆéªŒè¯å‡†ç¡®ç‡: {final_metrics['val_acc']:.4f}")
            print(f"  æœ€ç»ˆè®­ç»ƒæŸå¤±: {final_metrics['train_loss']:.4f}")
            print(f"  æœ€ç»ˆéªŒè¯æŸå¤±: {final_metrics['val_loss']:.4f}")


def demonstrate_old_vs_new_approach():
    """
    å¯¹æ¯”å±•ç¤ºæ—§æ–¹æ³•å’Œæ–°æ–¹æ³•çš„åŒºåˆ«
    """
    print("\n" + "="*60)
    print("ğŸ“‹ æ—§æ–¹æ³• vs æ–°æ–¹æ³•å¯¹æ¯”")
    print("="*60)
    
    print("\nğŸ”´ æ—§æ–¹æ³•çš„é—®é¢˜:")
    print("1. éœ€è¦æ‰‹åŠ¨æ„é€ å¤æ‚çš„callback_logså­—å…¸")
    print("2. æ•°æ®é‡å¤ä¼ é€’ï¼Œå®¹æ˜“å‡ºé”™")
    print("3. å›è°ƒå‡½æ•°å‚æ•°å†—é•¿ï¼Œéš¾ä»¥ç»´æŠ¤")
    print("4. è®­ç»ƒå™¨å’Œå›è°ƒå‡½æ•°è€¦åˆåº¦é«˜")
    
    print("\nğŸŸ¢ æ–°æ–¹æ³•çš„ä¼˜åŠ¿:")
    print("1. å›è°ƒå‡½æ•°ç›´æ¥è®¿é—®è®­ç»ƒå™¨çš„training_results")
    print("2. ç®€åŒ–å‚æ•°ä¼ é€’ï¼Œå‡å°‘ä»£ç é‡å¤")
    print("3. æ›´æ¸…æ™°çš„èŒè´£åˆ†ç¦»")
    print("4. æ›´å®¹æ˜“æ‰©å±•å’Œç»´æŠ¤")
    
    print("\nğŸ’¡ æ ¸å¿ƒæ”¹è¿›:")
    print("- å›è°ƒå‡½æ•°é€šè¿‡self.get_training_results()ç›´æ¥è·å–æ•°æ®")
    print("- è®­ç»ƒå™¨é€šè¿‡callback_manager.set_trainer(self)è®¾ç½®å¼•ç”¨")
    print("- ä¸å†éœ€è¦æ„é€ å¤æ‚çš„logså­—å…¸")


def main():
    """
    ä¸»å‡½æ•°
    
    è¿è¡Œå›è°ƒç³»ç»Ÿä¼˜åŒ–ç¤ºä¾‹
    """
    print("ğŸ¯ ä¼˜åŒ–åçš„å›è°ƒç³»ç»Ÿæ¼”ç¤º")
    print("="*50)
    
    # å±•ç¤ºæ–°æ—§æ–¹æ³•å¯¹æ¯”
    demonstrate_old_vs_new_approach()
    
    # è¿è¡Œè®­ç»ƒæ¨¡æ‹Ÿ
    print("\n" + "="*50)
    print("ğŸƒâ€â™‚ï¸ å¼€å§‹è®­ç»ƒæ¨¡æ‹Ÿ")
    print("="*50)
    
    trainer = MockTrainer()
    trainer.simulate_training(epochs=15)
    
    print("\n" + "="*50)
    print("âœ¨ æ¼”ç¤ºå®Œæˆï¼")
    print("="*50)
    print("\nğŸ“ æ€»ç»“:")
    print("- å›è°ƒå‡½æ•°ç°åœ¨å¯ä»¥ç›´æ¥è®¿é—®è®­ç»ƒå™¨çš„æ•°æ®")
    print("- ä¸å†éœ€è¦å¤æ‚çš„å‚æ•°ä¼ é€’")
    print("- ä»£ç æ›´ç®€æ´ã€æ›´æ˜“ç»´æŠ¤")
    print("- æ‰©å±•æ€§æ›´å¥½ï¼Œæ˜“äºæ·»åŠ æ–°çš„å›è°ƒåŠŸèƒ½")


if __name__ == "__main__":
    main()